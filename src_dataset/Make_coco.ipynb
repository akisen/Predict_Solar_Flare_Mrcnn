{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1602133273692",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "c1adb5375f229d1eea2415024ee773cb2493614d24a9913a0f46472292080f4e"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MaskデータをCOCOフォーマットに変換して学習用のデータセットを作成する\n",
    "[参考:COCO Formatの作り方](https://qiita.com/harmegiddo/items/da131ae5bcddbbbde41f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## フォーマット\n",
    "データ全体のフォーマットは以下の通り  \n",
    "今回必要そうなのは、  \n",
    "- Info\n",
    "- Images\n",
    "- Annotations\n",
    "```JSON\n",
    "{\n",
    "    \"info\": {...},\n",
    "    \"licenses\": [...],\n",
    "    \"images\": [...],\n",
    "    \"annotations\": [...],\n",
    "    \"categories\": [...], <-- Not in Captions annotations\n",
    "    \"segment_info\": [...] <-- Only in Panoptic annotations\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info部分の作成\n",
    "あってもなくてもいいがデータセットの内容について記述するために用意する\n",
    "\n",
    "### フォーマット\n",
    "```JSON\n",
    "\"info\": {\n",
    "    \"description\": \"COCO 2017 Dataset\",\n",
    "    \"url\": \"http://cocodataset.org\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"year\": 2017,\n",
    "    \"contributor\": \"COCO Consortium\",\n",
    "    \"date_created\": \"2017/09/01\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info部分の作成\n",
    "import json\n",
    "import collections as cl\n",
    "\n",
    "def info():\n",
    "    tmp = cl.OrderedDict() # OrderedDict:値を追加した順序を記憶することができる辞書型風のデータ構造を提供\n",
    "    tmp[\"descripion\"] = \"Predicting_Solar_Flare\"\n",
    "    tmp[\"version\"] = \"0.1\"\n",
    "    tmp[\"year\"] = 2020\n",
    "    tmp[\"contributor\"] = \"Akito Komatsu\"\n",
    "    tmp[\"data_created\"] = \"2020/09/01\"\n",
    "    return tmp\n",
    "    \n",
    "def main():\n",
    "    query_list = [\"info\",\"images\",\"annotations\"]\n",
    "    js = cl.OrderedDict()\n",
    "    for i in range (len(query_list)):\n",
    "        tmp = \"\"\n",
    "        if query_list[i] == \"info\":\n",
    "            tmp =info()\n",
    "        \n",
    "        js[query_list[i]] = tmp\n",
    "    fw = open(\"datasets.json\",\"w\")\n",
    "    json.dump(js,fw,indent=2)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'info': {'descripion': 'Predicting_Solar_Flare',\n  'version': '0.1',\n  'year': 2020,\n  'contributor': 'Akito Komatsu',\n  'data_created': '2020/09/01'},\n 'images': '',\n 'annotations': ''}"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "dataset_obj = open(\"datasets.json\",\"r\")\n",
    "dataset_json =json.load(dataset_obj)\n",
    "dataset_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imagesの作成\n",
    "IDはユニークで後のAnnotation等に関連付けられる  \n",
    "→time？検討\n",
    "フォーマット\n",
    "```JSON\n",
    "\"images\": [\n",
    "    {\n",
    "        \"license\": 4,\n",
    "        \"file_name\": \"000000397133.jpg\",\n",
    "        \"coco_url\": \"http://images.cocodataset.org/val2017/000000397133.jpg\",\n",
    "        \"height\": 427,\n",
    "        \"width\": 640,\n",
    "        \"date_captured\": \"2013-11-14 17:02:52\",\n",
    "        \"flickr_url\": \"http://farm7.staticflickr.com/6116/6255196340_da26cf2c9e_z.jpg\",\n",
    "        \"id\": 397133\n",
    "    },\n",
    "    {\n",
    "        \"license\": 1,\n",
    "        \"file_name\": \"000000037777.jpg\",\n",
    "        \"coco_url\": \"http://images.cocodataset.org/val2017/000000037777.jpg\",\n",
    "        \"height\": 230,\n",
    "        \"width\": 352,\n",
    "        \"date_captured\": \"2013-11-14 20:55:31\",\n",
    "        \"flickr_url\": \"http://farm9.staticflickr.com/8429/7839199426_f6d48aa585_z.jpg\",\n",
    "        \"id\": 37777\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = \"/home/akito/Documents/Documents/Predict_Solar_Flare_Mrcnn/samples/sun/HMI_REGION/*.fits\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def images(path):\n",
    "    tmps = []\n",
    "    for path in paths:\n",
    "        tmp = cl.OrderedDict()\n",
    "        tmp[\"id\"] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像データの作成\n",
    "そもそもCOCOフォーマットのデータを作成する前に画像データ自体を作成しなければならないので指定のフォーマットのデータを作成できるようにする流れは \n",
    "- [ ] FITSファイルから画像データの書き出し\n",
    "- [ ] FITSファイルのメタデータから必要なものを抜きだす\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# そもそもの画像の方のデータセットも同時に作る\n",
    "# from glob import glob\n",
    "# import sunpy.map\n",
    "# import cv2\n",
    "# fits_path = \"/media/akito/Data/HMI_REGION/2010/*2010050*\"\n",
    "# paths = sorted(glob(fits_path))\n",
    "# for i, path in enumerate(paths):\n",
    "#     # filename=\"/home/akito/Documents/Documents/Predict_Solar_Flare_Mrcnn/Dataset/Sun/Image/\"+path.split(\".\")[2][0:15]+\".jpg\"\n",
    "#     filename=\"/home/akito/Documents/Documents/Predict_Solar_Flare_Mrcnn/Dataset/Sun/Image/forffmpeg/\"+str(i).zfill(3)+\".jpg\"\n",
    "#     map=sunpy.map.Map(path)\n",
    "#     print(filename)\n",
    "#     cv2.imwrite(filename,cv2.flip(map.data,1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 画像のフォーマットについて\n",
    "Numpyを書き出したら白黒の4k4kのデータになっているがこれで大丈夫そうか？  \n",
    "→大丈夫そう"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotaionの付与について\n",
    "Pickleの吐き出しまでは良さそうなのでAnnotationをつけるとところをやっていく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み出し\n",
    "import utils \n",
    "path = \"/Users/komatsu/Documents/Predict_Solar_Flare_Mrcnn/coord_df.pickle\"\n",
    "coord_df = utils.pickle_load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Polygon  C_FLARE  M_FLARE  X_FLARE\n2010-05-01 00:00:00        6        6        6        6\n2010-05-01 01:00:00        5        5        5        5\n2010-05-01 02:00:00        4        4        4        4\n2010-05-01 03:00:00        4        4        4        4\n2010-05-01 04:00:00        4        4        4        4\n...                      ...      ...      ...      ...\n2019-12-31 20:00:00        0        0        0        0\n2019-12-31 21:00:00        0        0        0        0\n2019-12-31 22:00:00        0        0        0        0\n2019-12-31 23:00:00        0        0        0        0\n2020-01-01 00:00:00        0        0        0        0\n\n[84769 rows x 4 columns]\n"
    }
   ],
   "source": [
    "# Polygonとそれぞれのフレアデータが正しく入っているか確認\n",
    "f_len = lambda x : [len(cell) for cell in x]\n",
    "print(coord_df.apply(f_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3834.0\n[421.0, 2913.0, 68.0, 115.0]\n2010-05-01 00:00:00\n951.0\n[1395.0, 2660.0, 53.0, 24.0]\n2010-05-01 00:00:00\n5151.0\n[1226.0, 2646.0, 130.0, 53.0]\n2010-05-01 00:00:00\n16580.0\n[1297.0, 2760.0, 169.0, 133.0]\n2010-05-01 00:00:00\n15289.0\n[2283.0, 1262.0, 253.0, 80.0]\n2010-05-01 00:00:00\n15065.0\n[2006.0, 1181.0, 171.0, 109.0]\n2010-05-01 00:00:00\n4678.0\n[421.0, 2909.0, 74.0, 120.0]\n2010-05-01 01:00:00\n10006.0\n[1237.0, 2640.0, 230.0, 63.0]\n2010-05-01 01:00:00\n19599.0\n[1312.0, 2722.0, 173.0, 173.0]\n2010-05-01 01:00:00\n16049.0\n[2299.0, 1260.0, 256.0, 82.0]\n2010-05-01 01:00:00\n17109.0\n[2021.0, 1176.0, 182.0, 117.0]\n2010-05-01 01:00:00\n5147.0\n[426.0, 2909.0, 77.0, 122.0]\n2010-05-01 02:00:00\n31692.0\n[1253.0, 2639.0, 249.0, 258.0]\n2010-05-01 02:00:00\n16229.0\n[2314.0, 1259.0, 258.0, 84.0]\n2010-05-01 02:00:00\n17482.0\n[2036.0, 1175.0, 184.0, 119.0]\n2010-05-01 02:00:00\n5482.0\n[431.0, 2909.0, 79.0, 123.0]\n2010-05-01 03:00:00\n33325.0\n[1268.0, 2638.0, 251.0, 259.0]\n2010-05-01 03:00:00\n16577.0\n[2330.0, 1259.0, 256.0, 87.0]\n2010-05-01 03:00:00\n17699.0\n[2052.0, 1174.0, 183.0, 120.0]\n2010-05-01 03:00:00\n5697.0\n[437.0, 2911.0, 80.0, 120.0]\n2010-05-01 04:00:00\n34564.0\n[1284.0, 2637.0, 256.0, 260.0]\n2010-05-01 04:00:00\n16779.0\n[2346.0, 1258.0, 254.0, 89.0]\n2010-05-01 04:00:00\n18430.0\n[2068.0, 1172.0, 189.0, 123.0]\n2010-05-01 04:00:00\n5883.0\n[442.0, 2911.0, 82.0, 121.0]\n2010-05-01 05:00:00\n35272.0\n[1300.0, 2637.0, 259.0, 260.0]\n2010-05-01 05:00:00\n16947.0\n[2361.0, 1257.0, 254.0, 90.0]\n2010-05-01 05:00:00\n8047.0\n[2361.0, 1257.0, 286.0, 94.0]\n2010-05-01 05:00:00\n19069.0\n[2083.0, 1172.0, 196.0, 123.0]\n2010-05-01 05:00:00\n5977.0\n[449.0, 2913.0, 83.0, 119.0]\n2010-05-01 06:00:00\n36291.0\n[1317.0, 2637.0, 260.0, 261.0]\n2010-05-01 06:00:00\n16900.0\n[2377.0, 1257.0, 253.0, 90.0]\n2010-05-01 06:00:00\n19014.0\n[2099.0, 1172.0, 194.0, 123.0]\n2010-05-01 06:00:00\n6040.0\n[456.0, 2914.0, 83.0, 118.0]\n2010-05-01 07:00:00\n36681.0\n[1333.0, 2637.0, 262.0, 262.0]\n2010-05-01 07:00:00\n16813.0\n[2392.0, 1257.0, 253.0, 90.0]\n2010-05-01 07:00:00\n19048.0\n[2114.0, 1172.0, 196.0, 122.0]\n2010-05-01 07:00:00\n6023.0\n[463.0, 2916.0, 83.0, 117.0]\n2010-05-01 08:00:00\n36702.0\n[1351.0, 2638.0, 263.0, 262.0]\n2010-05-01 08:00:00\n16577.0\n[2408.0, 1258.0, 251.0, 88.0]\n2010-05-01 08:00:00\n18950.0\n[2130.0, 1172.0, 194.0, 122.0]\n2010-05-01 08:00:00\n5902.0\n[470.0, 2919.0, 82.0, 114.0]\n2010-05-01 09:00:00\n36423.0\n[1368.0, 2639.0, 263.0, 261.0]\n2010-05-01 09:00:00\n16269.0\n[2423.0, 1259.0, 250.0, 86.0]\n2010-05-01 09:00:00\n18999.0\n[2145.0, 1171.0, 195.0, 123.0]\n2010-05-01 09:00:00\n"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from shapely.geometry import Polygon\n",
    "def annotations(pickle_path):\n",
    "    tmps = []\n",
    "    coord_df = pd.read_pickle(pickle_path)\n",
    "    coord_df.apply(make_annotation_line,tmp=tmps,axis=1)\n",
    "    # print(coord_df.iloc[0][\"Polygon\"][0][0][0])\n",
    "    # return tmps\n",
    "\n",
    "def make_annotation_line(line,tmp):\n",
    "    for i in range(len(line[\"Polygon\"])):\n",
    "        polygon = Polygon(line[\"Polygon\"][i])\n",
    "        bb_coord = polygon.bounds\n",
    "        print(polygon.area)\n",
    "        bbox = [bb_coord[0],bb_coord[1],bb_coord[2]-bb_coord[0],bb_coord[3]-bb_coord[1]]\n",
    "        print(bbox)\n",
    "        print(line.name)\n",
    "        # TODO:Annotation完成させる\n",
    "\n",
    "annotations(\"/Users/komatsu/Documents/Predict_Solar_Flare_Mrcnn/coord_df.pickle\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}